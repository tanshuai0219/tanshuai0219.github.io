<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN" "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" class="gr__xh-liu_github_io">

<head>
  <link rel="icon" type="image/x-icon" href="figs\accept.png">
  <meta name="keywords" content="Shuai Tan, CS, SJTU, 谭帅">
  <meta name="description" content="Personal page of Shuai Tan at SJTU">
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <link rel="stylesheet" href="jemdoc.css" type="text/css">
  <script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
  <title>Shuai Tan's Homepage </title>
</head>

<body data-gr-c-s-loaded="true">
  <table summary="Table for page layout." id="tlayout">
    <tbody>
      <tr valign="top">
        <td id="layout-menu">
          <div class="menu-category">menu</div>
          <div class="menu-item"><a href="https://tanshuai0219.github.io/index.html" class="current">Home</a></div>
          <div class="menu-item"><a href="">Resume</a></div>
        </td>
        <td id="layout-content">
          <div id="toptitle">
            <h1>Shuai Tan(谭帅)</h1>
          </div>
          <table class="imgtable">
            <tbody>
              <tr>
                <td>
                  <img src="homepage2.jpg" alt="Shuai Tan" width="150px" height="200px">&nbsp;
                </td>
                <td align="left">
                  <p>Ph.D Candidate<br>
                    <!-- <a href="https://vis.baidu.com/#/">Department of Computer Vision Technology (VIS)</a> <br>
<a href="https://home.baidu.com/">Baidu Inc.</a><br> -->
                    <a>Shanghai Jiao Tong University</a> <br>
                    <a>Sichuan University</a><br>

                    tanshuai0219@sjtu.edu.cn <br>
                    tanshuai0219@outlook.com <br> <br>
                    <a href="https://github.com/tanshuai0219">Github</a>&nbsp;&nbsp;&nbsp;&nbsp;<a
                      href="https://scholar.google.com.hk/citations?user=9KjKwDwAAAAJ&hl=zh-CN">Scholar</a>
                  </p>
                </td>
              </tr>
            </tbody>
          </table>
          <h2>About me</h2>
          <p>I am currently pursuing the Ph.D degree in Computer Science and Engineering at <a
              href="https://www.sjtu.edu.cn/">Shanghai Jiao Tong University (SJTU)</a>.
            I received my bachelor degree in College of Software Engineering at <a
              href="https://www.scu.edu.cn/">Sichuan University (SCU)</a> in 2022.
            <br>
            <br>
            My research interests include deep learning and its applications on audio-visual learning, image/video
            generation, and virtual human creations.
            <br>
            <br>

            I plan to graduate with a PhD from Shanghai Jiao Tong University <span style="color:red; font-weight:bold;">in June 2026</span> and then pursue <span style="color:red; font-weight:bold;">postdoctoral research</span> ; if you are interested in my work and have a <span style="color:red; font-weight:bold;">suitable position</span>—particularly in the areas of digital human animation, AIGC, video generation/editing—<span style="color:red; font-weight:bold;">please feel free to contact me (tanshuai0219@outlook.com)</span>.

          </p>

          <h2>News</h2>
          <ul>

            <!-- <li>
              <p>[2025-02] One paper accepted to CVPR 2025, two collaborative paper accepted to CVPR 2025 </p>
            </li> -->

            <li>
              <p>[2025-02] One collaborative paper accepted to VR 2025 with Best Papers - Honorable Mentions.</p>
            </li>

            <li>
              <p>[2025-02] One collaborative paper accepted to TVCG 2025.</p>
            </li>
            
            <!-- <li>
              <p>[2025-01] One paper accepted to ICLR 2025.</p>
            </li>
            <li> -->

            <!-- <li>
              <p>[2024-09] One paper accepted to NeurIPS 2024.</p>
            </li>
            <li> -->

            <li>
              <p>[2024-07] One paper accepted to ECCV 2024 (Oral).</p>
            </li>
            <li>
              <p>[2024-02] One paper accepted to CVPR 2024.</p>
            </li>
            <li>
              <p>[2024-02] One collaborative paper accepted to TVCG 2024.</p>
            </li>
            <li>
              <p>[2023-12] Two papers accepted to AAAI 2024.</p>
            </li>
            <li>
              <p>[2023-07] One paper accepted to ICCV 2023.</p>
            </li>
            <li>
              <p>[2023-05] One collaborative paper accepted to KBS 2023.</p>
            </li>
            <li>
              <p>[2023-05] One collaborative paper accepted to IJNS 2023.</p>
            </li>
            <li>
              <p>[2023-02] One collaborative paper accepted to TVCG 2023.</p>
            </li>
            <li>
              <p>[2021-06] One paper accepted to MICCAI 2021.</p>
            </li>
          </ul>
          <h2>Publications</h2>
          <ul>
            <!-- <p>*Equal contribition, †Corresponding author</p> -->


            <!-- <table class="imgtable">
              <tbody>
                <tr>
                  <td>
                    <img src="figs/mimir.png" alt="mimir" width="180px">&nbsp;
                  </td>
                  <td align="left"><b><style="font-size:100%">
                        <a>Mimir: Improving Video Diffusion Models for Precise Text Understanding</a></b> <br>
                    <b>Shuai Tan</b>, Biao Gong, Yutong Feng, Kecheng Zheng, DanDan Zheng, Shuwei Shi, Yujun Shen, Jingdong Chen, Ming Yang <br>
                    <i>IEEE / CVF Computer Vision and Pattern Recognition Conference (CVPR) 2025.</i><br>
                    <a
                      href="https://arxiv.org/pdf/2412.03085">PDF</a>&nbsp;&nbsp;
                  </td>
                </tr>
              </tbody>
            </table>

            <table class="imgtable">
              <tbody>
                <tr>
                  <td>
                    <img src="figs/pomp.png" alt="pomp" width="180px">&nbsp;
                  </td>
                  <td align="left"><b><style="font-size:100%">
                        <a>POMP: Physics-consistent Human Motion Prior through Phase Manifolds</a></b> <br>
                        Bin Ji, Ye Pan, zhimeng Liu, <b>Shuai Tan</b>, Xiaogang Jin, Xiaokang Yang <br>
                    <i>IEEE / CVF Computer Vision and Pattern Recognition Conference (CVPR) 2025.</i><br>
                    <a
                      href="">PDF</a>&nbsp;&nbsp;
                  </td>
                </tr>
              </tbody>
            </table>

            <table class="imgtable">
              <tbody>
                <tr>
                  <td>
                    <img src="figs/motionstone.png" alt="motionstone" width="180px">&nbsp;
                  </td>
                  <td align="left"><b><style="font-size:100%">
                        <a>MotionStone: Decoupled Motion Intensity Modulation with Diffusion Transformer for Image-to-Video Generation</a></b> <br>
                        Shuwei Shi, Biao Gong, Xi Chen, DanDan Zheng, <b>Shuai Tan</b>, Zizheng Yang, Yuyuan Li, Jingwen He, Kecheng Zheng, Jingdong Chen, Ming Yang, Yinqiang Zheng <br>
                    <i>IEEE / CVF Computer Vision and Pattern Recognition Conference (CVPR) 2025.</i><br>
                    <a
                      href="https://arxiv.org/pdf/2412.05848">PDF</a>&nbsp;&nbsp;
                  </td>
                </tr>
              </tbody>
            </table> -->

            <table class="imgtable">
              <tbody>
                <tr>
                  <td>
                    <img src="figs/VASA-Rigs.png" alt="VASA-Rigs" width="180px">&nbsp;
                  </td>
                  <td align="left"><b><style="font-size:100%">
                        <a href="">VASA-Rig: Audio-Driven 3D Facial Animation with 'Live' Mood Dynamics
                          in Virtual Reality</a></b> <br>
                          Ye Pan, Chang Liu, Sicheng Xu, <b>Shuai Tan</b>, Jiaolong Yang <br>
                    <i>IEEE Conference on Virtual Reality and 3D User Interfaces (VR) 2025, Best Papers - Honorable Mentions.</i><br>
                    <a href="">PDF</a>&nbsp;&nbsp;
                  </td>
                </tr>
              </tbody>
            </table>

            <table class="imgtable">
              <tbody>
                <tr>
                  <td>
                    <img src="figs/tvcg_sport.png" alt="tvcg_sport" width="180px">&nbsp;
                  </td>
                  <td align="left"><b><style="font-size:100%">
                        <a href="https://ieeexplore.ieee.org/abstract/document/10891181">SPORT: From Zero-Shot Prompts to Real-Time Motion Generation</a></b> <br>
                          Bin Ji, Ye Pan, Zhimeng Liu, <b>Shuai Tan</b>, Xiaokang Yang <br>
                    <i>IEEE Transactions on Visualization and Computer Graphics (TVCG) 2025.</i><br>
                    <a href="https://ieeexplore.ieee.org/abstract/document/10891181">PDF</a>&nbsp;&nbsp;
                    <!-- <a href="https://hangz-nju-cuhk.github.io/projects/ReEnFP">Project</a>&nbsp;&nbsp; -->
                  </td>
                </tr>
              </tbody>
            </table>

            <!-- <table class="imgtable">
              <tbody>
                <tr>
                  <td>
                    <img src="figs\animate-x.png" alt="Animate-X" width="180px">&nbsp;
                  </td>
                  <td align="left"><b><style="font-size:100%">
                        <a>Animate-X: Universal Character Image Animation with Enhanced Motion Representation</a></b> <br>
                        <b>Shuai Tan</b>, Biao Gong, Xiang Wang, Shiwei Zhang, Dandan Zheng, Ruobin Zheng, Kecheng Zheng, Jingdong Chen,  Ming Yang <br>
                    <i>The International Conference on Learning Representations (ICLR) 2025. </i>
                    <br>
                    <a href="arXiv preprint arXiv:2410.10306">PDF</a>&nbsp;&nbsp;
                    <a href="https://lucaria-academy.github.io/Animate-X/">Project</a>&nbsp;&nbsp
                    <a href="https://github.com/Lucaria-Academy/Animate-X">Code</a>

                  </td>
                </tr>
              </tbody>
            </table> -->

            <!-- <table class="imgtable">
              <tbody>
                <tr>
                  <td>
                    <img src="figs\UKnow.png" alt="UKnow" width="180px">&nbsp;
                  </td>
                  <td align="left"><b><style="font-size:100%">
                        <a>UKnow: A Unified Knowledge Protocol with Multimodal Knowledge Graph Datasets for Reasoning and Vision-Language Pre-Training</a></b> <br>
                        Biao Gong, <b>Shuai Tan</b>, Yutong Feng, Xiaoying Xie, Yuyuan Li, Chaochao Chen, Kecheng Zheng, Yujun Shen, Deli Zhao <br>
                    <i>Annual Conference on Neural Information Processing Systems (NeurIPS) 2024. </i>
                    <br>
                    <a href="https://arxiv.org/pdf/2302.06891">PDF</a>&nbsp;&nbsp;
                  </td>
                </tr>
              </tbody>
            </table> -->


            <table class="imgtable">
              <tbody>
                <tr>
                  <td>
                    <img src="figs/EDTalk.svg" alt="EDTalk" width="180px">&nbsp;
                  </td>
                  <td align="left"><b><style="font-size:100%">
                        <a>EDTalk: Efficient Disentanglement for Emotional Talking Head Synthesis</a></b> <br>
                    <b>Shuai Tan</b>, Bin Ji, Mengxiao Bi, Ye Pan <br>
                    <i>European Conference on Computer Vision (ECCV) 2024 (Oral). </i>
                    <br>
                    <a href="https://link.springer.com/chapter/10.1007/978-3-031-72658-3_23">PDF</a>&nbsp;&nbsp;
                    <a href="https://tanshuai0219.github.io/EDTalk/">Project</a>&nbsp;&nbsp
                    <a href="https://github.com/tanshuai0219/EDTalk">Code</a> <a href="https://github.com/tanshuai0219/EDTalk">
                      <img src="https://img.shields.io/github/stars/tanshuai0219/EDTalk?style=social" alt="GitHub Stars">
                    </a>
                    <a href="https://github.com/tanshuai0219/EDTalk">
                      <img src="https://img.shields.io/github/forks/tanshuai0219/EDTalk?style=social" alt="GitHub Forks">
                    </a>
                  </td>
                </tr>
              </tbody>
            </table>


            <table class="imgtable">
              <tbody>
                <tr>
                  <td>
                    <img src="figs/flowvqtalker.png" alt="flowvqtalker" width="180px">&nbsp;
                  </td>
                  <td align="left"><b><style="font-size:100%">
                        <a>FlowVQTalker: High-Quality Emotional Talking Face Generation through Normalizing Flow and
                          Quantization</a></b> <br>
                    <b>Shuai Tan</b>, Bin Ji, Ye Pan <br>
                    <i>IEEE / CVF Computer Vision and Pattern Recognition Conference (CVPR) 2024.</i><br>
                    <a
                      href="https://openaccess.thecvf.com/content/CVPR2024/html/Tan_FlowVQTalker_High-Quality_Emotional_Talking_Face_Generation_through_Normalizing_Flow_and_CVPR_2024_paper.html">PDF</a>&nbsp;&nbsp;
                    <!-- <a href="https://dreamgaussian.github.io/">Project</a>&nbsp;&nbsp
          <a href="https://github.com/dreamgaussian/dreamgaussian">Code</a> -->
                  </td>
                </tr>
              </tbody>
            </table>

            <table class="imgtable">
              <tbody>
                <tr>
                  <td>
                    <img src="figs/tvcg2024.png" alt="tvcg2024" width="180px">&nbsp;
                  </td>
                  <td align="left"><b><style="font-size:100%">
                        <a>Expressive Talking Avatars</a></b> <br>
                    Ye Pan, <b>Shuai Tan</b>, Shengran Cheng, Qunfen Lin, Zijiao Zeng, Kenny Mitchell <br>
                    <i>IEEE Transactions on Visualization and Computer Graphics (TVCG) 2024.</i><br>
                    <a href="https://ieeexplore.ieee.org/abstract/document/10458318/">PDF</a>&nbsp;&nbsp;
                    <!-- <a href="https://dreamgaussian.github.io/">Project</a>&nbsp;&nbsp
          <a href="https://github.com/dreamgaussian/dreamgaussian">Code</a> -->
                  </td>
                </tr>
              </tbody>
            </table>

            <table class="imgtable">
              <tbody>
                <tr>
                  <td>
                    <img src="figs/saas.png" alt="saas" width="180px">&nbsp;
                  </td>
                  <td align="left"><b><style="font-size:100%">
                        <a>Say Anything with Any Style</a></b> <br>
                    <b>Shuai Tan</b>, Bin Ji, Yu Ding, Ye Pan <br>
                    <i>AAAI Conference on Artificial Intelligence (AAAI) 2024.</i><br>
                    <a href="https://ojs.aaai.org/index.php/AAAI/article/view/28314">PDF</a>&nbsp;&nbsp;
                    <!-- <a href="https://dreamgaussian.github.io/">Project</a>&nbsp;&nbsp -->
                    <a href="https://github.com/tanshuai0219/SAAS">Code</a>
                  </td>
                </tr>
              </tbody>
            </table>


            <table class="imgtable">
              <tbody>
                <tr>
                  <td>
                    <img src="figs/style2talker.png" alt="style2talker" width="180px">&nbsp;
                  </td>
                  <td align="left"><b><style="font-size:100%">
                        <a>Style<sup>2</sup>Talker: High-Resolution Talking Head Generation with Emotion Style and Art
                          Style</a></b> <br>
                    <b>Shuai Tan</b>, Bin Ji, Ye Pan <br>
                    <i>AAAI Conference on Artificial Intelligence (AAAI) 2024.</i><br>
                    <a href="https://ojs.aaai.org/index.php/AAAI/article/view/28313">PDF</a>&nbsp;&nbsp;
                    <!-- <a href="https://dreamgaussian.github.io/">Project</a>&nbsp;&nbsp -->
                    <a href="https://github.com/tanshuai0219/style2talker">Code</a>
                  </td>
                </tr>
              </tbody>
            </table>

            <table class="imgtable">
              <tbody>
                <tr>
                  <td>
                    <img src="figs/emmn.png" alt="emmn" width="180px">&nbsp;
                  </td>
                  <td align="left"><b><style="font-size:100%">
                        <a
                          href="http://openaccess.thecvf.com/content/ICCV2023/html/Tan_EMMN_Emotional_Motion_Memory_Network_for_Audio-driven_Emotional_Talking_Face_ICCV_2023_paper.html">EMMN:
                          Emotional Motion Memory Network for Audio-driven Emotional Talking Face Generation</a></b>
                    <br>
                    <b>Shuai Tan</b>, Bin Ji, Ye Pan <br>
                    <i>International Conference on Computer Vision (ICCV) 2023.</i><br>
                    <a
                      href="http://openaccess.thecvf.com/content/ICCV2023/html/Tan_EMMN_Emotional_Motion_Memory_Network_for_Audio-driven_Emotional_Talking_Face_ICCV_2023_paper.html">PDF</a>&nbsp;&nbsp;
                    <!-- <a href="">Project</a>&nbsp;&nbsp -->
                  </td>
                </tr>
              </tbody>
            </table>

            <table class="imgtable">
              <tbody>
                <tr>
                  <td>
                    <img src="figs/kbs.png" alt="kbs" width="180px">&nbsp;
                  </td>
                  <td align="left"><b><style="font-size:100%">
                        <a href="https://www.sciencedirect.com/science/article/pii/S0950705123003489">Uncertainty-weighted
                          and relation-driven consistency training for semi-supervised head-and-neck tumor
                          segmentation</a></b> <br>
                    Yuang Shi, Chen Zu, Pinli Yang, <b>Shuai Tan</b>, Hongping Ren, Xi Wu, Jiliu Zhou, Yan Wang <br>
                    <i>Knowledge-Based Systems (KBS) 2023.</i><br>
                    <a href="https://www.sciencedirect.com/science/article/pii/S0950705123003489">PDF</a>&nbsp;&nbsp;
                    <!-- <a href="https://hangz-nju-cuhk.github.io/projects/StyleSync">Project</a>&nbsp;&nbsp -->
                  </td>
                </tr>
              </tbody>
            </table>

            <table class="imgtable">
              <tbody>
                <tr>
                  <td>
                    <img src="figs/ijns.png" alt="ijns" width="180px">&nbsp;
                  </td>
                  <td align="left"><b><style="font-size:100%">
                        <a href="https://europepmc.org/article/med/37420338">A Transformer-Embedded Multi-Task Model for
                          Dose Distribution Prediction</a></b> <br>
                    Lu Wen, Jianghong Xiao, <b>Shuai Tan</b>, Xi Wu, Jiliu Zhou, Xingchen Peng, Yan Wang <br>
                    <i>International Journal of Neural Systems (IJNS) 2023.</i><br>
                    <a href="https://europepmc.org/article/med/37420338">PDF</a>&nbsp;&nbsp;
                    <!-- <a href="">Project</a>&nbsp;&nbsp -->
                  </td>
                </tr>
              </tbody>
            </table>


            <table class="imgtable">
              <tbody>
                <tr>
                  <td>
                    <img src="figs/evp.png" alt="evp" width="180px">&nbsp;
                  </td>
                  <td align="left"><b><style="font-size:100%">
                        <a href="https://ieeexplore.ieee.org/abstract/document/10049691/">Emotional Voice
                          Puppetry</a></b> <br>
                    Ye Pan, Ruisi Zhang, Shengran Cheng, <b>Shuai Tan</b>, Yu Ding, Kenny Mitchell, Xubo Yang <br>
                    <i>IEEE Transactions on Visualization and Computer Graphics (TVCG) 2023.</i><br>
                    <a href="https://ieeexplore.ieee.org/abstract/document/10049691/">PDF</a>&nbsp;&nbsp;
                    <!-- <a href="https://hangz-nju-cuhk.github.io/projects/ReEnFP">Project</a>&nbsp;&nbsp; -->
                  </td>
                </tr>
              </tbody>
            </table>

            <table class="imgtable">
              <tbody>
                <tr>
                  <td>
                    <img src="figs/MICCAI.png" alt="MICCAI" width="180px">&nbsp;
                  </td>
                  <td align="left"><b><style="font-size:100%">
                        <a href="https://link.springer.com/chapter/10.1007/978-3-030-87234-2_71">Incorporating isodose
                          lines and gradient information via multi-task learning for dose prediction in
                          radiotherapy</a></b> <br>
                    <b>Shuai Tan</b>, Pin Tang, Xingchen Peng, Jianghong Xiao, Chen Zu, Xi Wu, Jiliu Zhou, Yan Wang <br>
                    <i>Medical Image Computing and Computer Assisted Intervention (MICCAI) 2021.</i><br>
                    <a href="https://link.springer.com/chapter/10.1007/978-3-030-87234-2_71">PDF</a>&nbsp;&nbsp;
                    <a href="https://github.com/tanshuai0219/MTDP-network">Code</a>&nbsp;&nbsp
                  </td>
                </tr>
              </tbody>
            </table>

            <h2>Professional Activities</h2>
            <ul>
            <!-- <li> Organizer of ECCV 2020 <a href="https://sense-human.github.io/">SenseHuman Workshop</a>
            </li> -->
            <li> Journal Reviewer of TMM, TCSVT.
            </li>
            <!-- <li> Conference Reviewer of ICCV, CVPR, ECCV, ICML, AAAI, NeurIPS, ICLR, Siggraph, etc.
            </li> -->
            </ul>

            <h2>Honors and Awards</h2>
            <ul>
              <li> 2024.12 John Centre PhD First Class Scholarship</a>
              </li>
              <li> 2024.10 National Scholarships for PhD students</a>
              </li>
              <li> 2023.12 John Centre PhD Second Class Scholarship</a>
              </li>
              <li> 2022.06 Outstanding Thesis of Sichuan University</a>
              </li>
            <li> 2022.05 Outstanding Graduates of Sichuan Province and Sichuan University</a>
            </li>
            <li> 2021.10 National Inspiration Scholarship</a>
            </li>
            <li> 2020.10 National Inspiration Scholarship</a>
            </li>
            <li> 2019.10 Tongxin Scholarship</a>
            </li>
            </ul>
            <p class="has-text-centered">Total clicks: <span id="busuanzi_value_site_pv"></span></p>
            

          </ul>
        </td>
      </tr>
    </tbody>
  </table>


</body>

</html>